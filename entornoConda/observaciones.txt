-Tanto en seleccion de numero de neurons como en numero de capas, poner sampling= log en caso de mucha distancia entre min y max? -No prioritario
-Para automatizar proceso. ¿Dejar información en un fichero que resuma precisión y loss para cada conjunto final de datos, es decir, para 100 epocas -> ver como son los resultados. Luego para 1000 y luego para 10000?
-AL llamar a Model ¿Pedir numero de batches obligatorio o numero de epocas o ninguno de ellos y fijar valor default?

poner bien la lr al cambiar de optimizador - Esta bien
Revisar que cada iteracion de hiperparametros guarde bien el valor -> Bien
Validation accuracy deberia ser menos que la accuracy de entrenamiento por lo general -> Problema ¿Aumentar porcentaje de validacion?

Fallo-> El numero de trials del optimizador debería ser como mínimo igual que la longitud de la lista que se le pasa (estaba puesto al numero de trials en general que habia). Es decir, hacerlo como la funcion de activacion. Ya hecho
Posible fallo -> Mejor probar optimizador con learning rate combinado y luego una eleccion por separado de lr
He modificado la heurística de búsqueda de select_optimizer_and_lr con la lr siendo self.lr/10 y self.lr*10, en vez de 100
En la nueva busqueda de lr (select_lr) si se busca entre +- 100